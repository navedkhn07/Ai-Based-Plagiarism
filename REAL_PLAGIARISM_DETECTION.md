# Real Plagiarism Detection Implementation

## What Was Changed

I've completely rewritten the plagiarism detection system to use **real web search** instead of fake/simulated results. The system now:

1. **Searches the web** for similar content using Google search
2. **Fetches actual web pages** and compares your text against them
3. **Calculates accurate percentages** based on real matches:
   - **Exact Match**: Text that matches 95%+ similarity
   - **Partial Match**: Text that matches 70-95% similarity
   - **Unique Content**: Original text with no matches
4. **Provides real source links** to where plagiarism was found
5. **Numbers matches correctly** (Match 1, Match 2, Match 3, etc.)

## New Features

### 1. Web Search Integration
- Uses Google search to find similar content online
- Extracts key phrases from your text to search
- Fetches actual web page content for comparison

### 2. Accurate Text Matching
- **Exact Match**: Finds text that matches 95%+ similarity
- **Partial Match**: Finds text that matches 70-95% similarity
- Uses advanced text comparison algorithms (SequenceMatcher)

### 3. Real Source Links
- Each match includes a clickable URL to the source
- Shows the actual website where similar content was found
- Displays source titles and matching text snippets

### 4. Accurate Percentages
- **Exact Match %**: Based on actual character count of exact matches
- **Partial Match %**: Based on actual character count of partial matches
- **Unique Content %**: Remaining original content
- **Total Plagiarism %**: Sum of exact + partial matches

## Installation

### Install New Python Dependencies

```bash
cd ai-service
pip install beautifulsoup4 googlesearch-python
```

Or install all dependencies:
```bash
pip install -r requirements.txt
```

### Install googlesearch-python

The `googlesearch-python` library is used for web searching. If you encounter issues:

```bash
pip install googlesearch-python
```

**Note**: Google may rate-limit searches. For production use, consider:
- Using Google Custom Search API (requires API key)
- Implementing rate limiting
- Using alternative search APIs

## How It Works

1. **Text Analysis**: Extracts sentences and key phrases from your text
2. **Web Search**: Searches Google for similar content using extracted phrases
3. **Content Fetching**: Downloads and parses web pages from search results
4. **Text Matching**: Compares your text against found content using:
   - Exact substring matching
   - SequenceMatcher for similarity scoring
   - Character-based percentage calculation
5. **Result Formatting**: Returns matches with:
   - Source URLs
   - Match types (exact/partial)
   - Similarity percentages
   - Matching text snippets

## API Response Format

The API now returns:

```json
{
  "similarity_score": 27.5,
  "plagiarism_percentage": 27.5,
  "exact_match_percentage": 24.0,
  "partial_match_percentage": 3.5,
  "unique_content_percentage": 72.5,
  "matches": [
    {
      "text": "The pathophysiology of hypertension involves...",
      "similarity": 95.2,
      "match_type": "exact",
      "source": "Journal of Hypertension",
      "url": "https://example.com/article",
      "match_number": 1
    }
  ]
}
```

## Frontend Updates

The frontend now displays:
- **Accurate percentages** from backend calculations
- **Color-coded highlighting**:
  - Red: Exact matches
  - Orange: Partial matches
  - Green: Unique content
- **Clickable source links** in expanded match details
- **Match numbering** (Match 1, Match 2, etc.)

## Testing

After installing dependencies and restarting the AI service:

1. **Test with known plagiarized text**:
   - Copy text from a Wikipedia article
   - Paste it into the checker
   - Should find matches with source links

2. **Test with original text**:
   - Write your own text
   - Should show low plagiarism percentage

3. **Check source links**:
   - Expand matches in results
   - Click "View Source" to verify URLs work

## Troubleshooting

### "ModuleNotFoundError: No module named 'googlesearch'"
**Fix**: Install the library
```bash
pip install googlesearch-python
```

### "No sources found" or "Web search not available"
**Possible causes**:
- Google rate limiting (too many requests)
- Network connectivity issues
- Library import errors

**Fallback**: System will use semantic similarity as backup

### Slow response times
**Reason**: Web search and content fetching takes time
**Solution**: 
- Be patient (can take 10-30 seconds)
- Consider implementing caching
- Use Google Custom Search API for faster results

## Production Considerations

For production use, consider:

1. **Google Custom Search API**: More reliable than web scraping
   - Requires API key
   - Has usage limits
   - More accurate results

2. **Rate Limiting**: Implement request throttling
   - Limit searches per user/IP
   - Cache results for duplicate texts

3. **Database Integration**: Store known sources
   - Compare against local database first
   - Only search web for new content

4. **Error Handling**: Better fallback mechanisms
   - Multiple search providers
   - Offline mode with cached sources

## Next Steps

1. Install new dependencies
2. Restart AI service
3. Test with sample text
4. Verify source links work
5. Check percentages are accurate

---

**The plagiarism checker now uses real web search and provides accurate, verifiable results!** ðŸŽ‰

